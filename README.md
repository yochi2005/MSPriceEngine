# MSPriceEngine ğŸ·ï¸

**Price Search Engine for Mexico** - Compare prices across major online stores in Mexico.

An open-source project to help Mexican consumers find the best prices by scraping and comparing products from Amazon MX, Walmart MX, Liverpool, and more.

## ğŸš€ Features

- âœ… REST API for product search
- âœ… Multiple store support (Amazon MX, Walmart MX, Liverpool)
- âœ… Automated daily price updates
- âœ… SQLite/PostgreSQL support
- âœ… Docker deployment ready
- âœ… Swagger UI documentation

## ğŸ“‹ Tech Stack

- **Backend**: Python 3.11+ with FastAPI
- **Database**: SQLite (dev) / PostgreSQL (prod)
- **Scraping**: httpx + BeautifulSoup4
- **Scheduler**: APScheduler
- **Deployment**: Docker + Docker Compose

## ğŸ› ï¸ Installation

### Option 1: Local Development

```bash
# Clone repository
git clone <repository-url>
cd MSPriceEngine

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run the application
uvicorn app.main:app --reload
```

### Option 2: Docker (Recommended)

```bash
# Build and run with Docker Compose
docker-compose up --build

# Access the API
open http://localhost:8000/docs
```

## ğŸ“– API Documentation

Once running, visit:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Example API Calls

**Search products:**
```bash
curl "http://localhost:8000/search?q=iphone&min_price=5000&max_price=20000"
```

**Get product details:**
```bash
curl "http://localhost:8000/products/1"
```

**List stores:**
```bash
curl "http://localhost:8000/stores"
```

## ğŸ“ Project Structure

```
MSPriceEngine/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ models.py            # Database models
â”‚   â”œâ”€â”€ schemas.py           # Pydantic schemas
â”‚   â”œâ”€â”€ database.py          # Database configuration
â”‚   â”œâ”€â”€ scheduler.py         # Scraping scheduler
â”‚   â””â”€â”€ scrapers/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base.py          # Base scraper class
â”‚       â”œâ”€â”€ amazon.py        # Amazon MX scraper
â”‚       â”œâ”€â”€ walmart.py       # Walmart MX scraper
â”‚       â””â”€â”€ liverpool.py     # Liverpool scraper
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ data/                    # SQLite database (gitignored)
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

Copy `.env.example` to `.env` and configure:

```env
# Database
DATABASE_URL=sqlite:///./data/price_search.db

# For PostgreSQL:
# DATABASE_URL=postgresql://user:password@localhost:5432/priceengine

# Scheduler
ENABLE_SCHEDULER=false
SCRAPING_HOUR=3
```

## ğŸ¤– Running Scrapers

The scheduler runs automatically at 3:00 AM daily. To manually trigger:

```python
from app.scheduler import scheduler
scheduler.run_now()
```

## ğŸ§ª Testing

```bash
# Install dev dependencies
pip install pytest pytest-asyncio

# Run tests
pytest
```

## ğŸ“Š Current Status

### Implemented âœ…
- Amazon MX scraper (basic)
- FastAPI REST API
- SQLite database
- Docker deployment
- Swagger documentation

### TODO ğŸš§
- Complete Walmart MX scraper (needs JS rendering)
- Complete Liverpool scraper
- Add more stores (Mercado Libre, Coppel, etc.)
- Price history tracking
- Product matching algorithm
- Tests suite
- CI/CD pipeline

## âš ï¸ Legal Disclaimer

This project is for **educational purposes only**. Web scraping may violate the Terms of Service of some websites. Always:
- Respect `robots.txt`
- Use reasonable rate limiting
- Don't overload servers
- Consult with a lawyer before production use

## ğŸ¤ Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“ License

MIT License - See LICENSE file for details

## ğŸ”— Links

- **Documentation**: Coming soon
- **Issues**: Report bugs on GitHub
- **Discussions**: Join our community

---

Made with â¤ï¸ for the Mexican tech community
